{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTlX57GsR-gb"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "!gcloud auth activate-service-account your_account --key-file=\"path_to_the_key\"\n",
        "# add your key here "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpdXIZJmSz7z"
      },
      "outputs": [],
      "source": [
        "!gcloud auth list\n",
        "!gcloud config set account your_account\n",
        "# activate your google cloud account here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uKqtLspRh02"
      },
      "outputs": [],
      "source": [
        "1\n",
        "from google.colab import auth\n",
        "# auth.authenticate_user()\n",
        "!gcloud init\n",
        "!gcloud auth list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukCNKzXDE2Zr",
        "outputId": "492c60eb-89c2-4607-c96c-7b0121ef095c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "               Credentialed Accounts\n",
            "ACTIVE  ACCOUNT\n",
            "*       lgx-602@gpt3-363020.iam.gserviceaccount.com\n",
            "\n",
            "To set the active account, run:\n",
            "    $ gcloud config set account `ACCOUNT`\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!gcloud auth list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uQGV1ulRuGha"
      },
      "outputs": [],
      "source": [
        "#@title Setup\n",
        "%tensorflow_version 2.x\n",
        "!git clone https://github.com/EleutherAI/GPTNeo\n",
        "%cd GPTNeo\n",
        "!pip3 install -q -r requirements.txt\n",
        "pretrained_model = None\n",
        "dataset = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Sl4lpIFuZNXB"
      },
      "outputs": [],
      "source": [
        "#@title Setup\n",
        "%tensorflow_version 2.x\n",
        "!git clone https://github.com/EleutherAI/GPTNeo\n",
        "%cd GPTNeo\n",
        "!pip3 install google-api-python-client\n",
        "!pip3 install jsonlines\n",
        "!pip3 install lm_dataformat\n",
        "!pip3 install mesh-tensorflow==0.1.18\n",
        "!pip3 install numpy==1.21.0\n",
        "!pip3 install oauth2client\n",
        "!pip3 install ortools\n",
        "!pip3 install pytest\n",
        "!pip3 install sacred\n",
        "!pip3 install tensorflow==2.5.1\n",
        "!pip3 install tensorflow-datasets==3.2.1\n",
        "!pip3 install tokenizers==0.9.4\n",
        "!pip3 install transformers==4.1.1\n",
        "!pip3 install tpunicorn\n",
        "# !pip3 install -q -r requirements.txt\n",
        "!pip3 install absl-py\n",
        "!pip3 install ftfy\n",
        "!pip3 install sacred\n",
        "!pip3 install pymongo\n",
        "# !pip3 install xarray-einstats==0.2.2\n",
        "# !pip3 install jax==0.3.17\n",
        "# !pip3 install cmdstanpy==1.0.7\n",
        "pretrained_model = None\n",
        "dataset = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBK6uVVxlR3-"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QKRZCYzWymi"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Fo6XBE0W0K3"
      },
      "outputs": [],
      "source": [
        "path_to_cloud_bucket = 'gs://gpt3_demo/' #@param {type:\"string\"}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6-xyJmWVc-Q"
      },
      "source": [
        "Set Up Dataset 1 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "hlNJ3_fS37LU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "dataset = \"Custom3\" #@param [\"Sampling_Only\", \"OpenWebText\", \"YoutubeSubtitles\", \"HackerNews\", \"NIHExporter\", \"Custom3\", \"Custom2\"]\n",
        "\n",
        "if dataset == \"Sampling_Only\":\n",
        "  pass\n",
        "elif dataset == \"Custom3\":\n",
        "  os.makedirs('data', exist_ok=True)\n",
        "  dataset_path = 'data'\n",
        "  dataset_name = 'code_to_requirement'\n",
        "  out_name = dataset_name + \"_tokenized\"\n",
        "elif dataset == 'YoutubeSubtitles':\n",
        "  os.makedirs('data', exist_ok=True)\n",
        "  # !wget https://the-eye.eu/public/AI/pile_preliminary_components/yt_subs.jsonl.zst -O data/yt_subs.jsonl.zst\n",
        "  dataset_path = 'data'\n",
        "  dataset_name = 'ytsubs'\n",
        "  out_name = dataset_name + \"_tokenized\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6PeQ6rGvO3h"
      },
      "source": [
        "Set Up Dataset 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LrWzaHOKXFtG"
      },
      "outputs": [],
      "source": [
        "# Select a Dataset:\n",
        "import os\n",
        "dataset = 'Custom' #@param [\"Sampling_Only\", \"OpenWebText\", \"YoutubeSubtitles\", \"HackerNews\", \"NIHExporter\", \"Custom\"]\n",
        "\n",
        "if dataset == \"Sampling_Only\":\n",
        "  pass\n",
        "elif dataset == 'OpenWebText':\n",
        "  !wget https://the-eye.eu/public/AI/pile_preliminary_components/openwebtext2.jsonl.zst.tar -O openwebtext.tar.xz\n",
        "  !tar xf openwebtext.tar.xz\n",
        "  dataset_path = \"openwebtext\"\n",
        "  dataset_name = dataset_path\n",
        "  out_name = dataset_name + \"_tokenized\"\n",
        "elif dataset == 'YoutubeSubtitles':\n",
        "  os.makedirs('data', exist_ok=True)\n",
        "  !wget https://the-eye.eu/public/AI/pile_preliminary_components/yt_subs.jsonl.zst -O data/yt_subs.jsonl.zst\n",
        "  dataset_path = 'data'\n",
        "  dataset_name = 'ytsubs'\n",
        "  out_name = dataset_name + \"_tokenized\"\n",
        "elif dataset == 'HackerNews':\n",
        "  os.makedirs('data', exist_ok=True)\n",
        "  !wget https://the-eye.eu/public/AI/pile_preliminary_components/hn.tar.gz -O data/hn.tar.gz\n",
        "  dataset_path = 'data'\n",
        "  dataset_name = 'hackernews'\n",
        "  out_name = dataset_name + \"_tokenized\"\n",
        "elif dataset == \"NIHExporter\":\n",
        "  os.makedirs('data', exist_ok=True)\n",
        "  !wget https://the-eye.eu/public/AI/pile_preliminary_components/NIH_ExPORTER_awarded_grant_text.jsonl.zst -O data/NIH_ExPORTER_awarded_grant_text.jsonl.zst\n",
        "  dataset_path = 'data'\n",
        "  os.system('mv NIH_ExPORTER_awarded_grant_text.jsonl.zst ./data')\n",
        "  dataset_name = 'nihexporter'\n",
        "  out_name = dataset_name + \"_tokenized\"\n",
        "elif dataset == \"Custom\":\n",
        "  os.makedirs('data', exist_ok=True)\n",
        "  dataset_path = 'data2'\n",
        "  dataset_name = 'code_to_uc'\n",
        "  out_name = dataset_name + \"_tokenized\"\n",
        "else:\n",
        "  raise NotImplementedError('please select from available options: [\"OpenWebText\", \"YoutubeSubtitles\", \"HackerNews\", \"NIHExporter\", \"Custom\"]')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLczBhpoWQS1"
      },
      "source": [
        "**Tokenize and Upload Data\n",
        "(skip this step if you are sampling from a pre-trained model).**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ietBGGg7XI3d"
      },
      "outputs": [],
      "source": [
        "# Tokenize Data\n",
        "!python data/create_tfrecords.py --input_dir /content/GPTNeo/data2/ --name $dataset_name --files_per 100 --output_dir ./tfrecords --write_dataset_config --processes 1\n",
        "\n",
        "# copy the data to your bucket\n",
        "if not path_to_cloud_bucket.endswith('/'):\n",
        "  path_to_cloud_bucket += '/'\n",
        "\n",
        "copy_loc = path_to_cloud_bucket + \"datasets/\" + dataset\n",
        "!gsutil -m cp -r ./tfrecords $copy_loc\n",
        "!gsutil ls $path_to_cloud_bucket"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BalLoVr9aVCn",
        "outputId": "3fdf1d77-2f4e-4991-8d53-ac419d496cca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing configs/dataset_configs/Custom.json\n"
          ]
        }
      ],
      "source": [
        "%%writefile configs/dataset_configs/Custom.json\n",
        "\n",
        "{\n",
        "  \"path\": \"gs://gpt3_demo/datasets/Custom/code_to_uc*.tfrecords\",\n",
        "  \"eval_path\": \"\",\n",
        "  \"n_vocab\": 50256,\n",
        "  \"tokenizer_is_pretrained\": true,\n",
        "  \"tokenizer_path\": \"gpt2\",\n",
        "  \"eos_id\": 50256,\n",
        "  \"padding_id\": 50257\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m50owUv7Zba_",
        "outputId": "aa1eb619-e4a8-46a4-bc69-c1ef0554b69f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing configs/dataset_configs/YoutubeSubtitles.json\n"
          ]
        }
      ],
      "source": [
        "%%writefile configs/dataset_configs/YoutubeSubtitles.json\n",
        "\n",
        "{\n",
        "  \"path\": \"gs://gpt3_demo/datasets/YoutubeSubtitles/ytsubs*.tfrecords\",\n",
        "  \"eval_path\": \"\",\n",
        "  \"n_vocab\": 50256,\n",
        "  \"tokenizer_is_pretrained\": true,\n",
        "  \"tokenizer_path\": \"gpt2\",\n",
        "  \"eos_id\": 50256,\n",
        "  \"padding_id\": 50257\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjgAE02tWYYP"
      },
      "source": [
        "Set Model Configs, do not skip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmRzibAuaKqy",
        "outputId": "9fac43db-5d53-4796-ee4e-e1d9a2357e9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing configs/GPT3_XL3.json\n"
          ]
        }
      ],
      "source": [
        "%%writefile configs/GPT3_XL3.json\n",
        "\n",
        "{\n",
        "    \"n_head\": 16,\n",
        "    \"n_vocab\": 50257,\n",
        "    \"embed_dropout\": 0,\n",
        "    \"lr\": 0.0002,\n",
        "    \"lr_decay\": \"cosine\",\n",
        "    \"warmup_steps\": 3000,\n",
        "    \"beta1\": 0.9,\n",
        "    \"beta2\": 0.95,\n",
        "    \"epsilon\": 1e-8,\n",
        "    \"opt_name\": \"adam\",\n",
        "    \"weight_decay\": 0,\n",
        "    \"train_batch_size\": 256,\n",
        "    \"attn_dropout\": 0,\n",
        "    \"train_steps\": 600000,\n",
        "    \"eval_steps\": 0,\n",
        "    \"predict_steps\": 1,\n",
        "    \"res_dropout\": 0,\n",
        "    \"eval_batch_size\": 4,\n",
        "    \"predict_batch_size\": 1,\n",
        "    \"iterations\": 100,\n",
        "    \"n_embd\": 2048,\n",
        "    \"datasets\": [\"Custom\"],\n",
        "    \"model\": \"GPT\",\n",
        "    \"model_path\": \"gs://gpt3_demo/GPT3_XL3\",\n",
        "    \"n_ctx\": 2048,\n",
        "    \"n_layer\": 24,\n",
        "    \"scale_by_depth\": true,\n",
        "    \"scale_by_in\": false,\n",
        "    \"attention_types\" :  [[[\"global\", \"local\"],12]],\n",
        "    \"mesh_shape\": \"x:4,y:2\",\n",
        "    \"layout\": \"intermediate_expanded:x,heads:x,vocab:n_vocab,memory_length:y,embd:y\",\n",
        "    \"activation_function\": \"gelu\",\n",
        "    \"recompute_grad\": true,\n",
        "    \"gradient_clipping\": 1.0,\n",
        "    \"tokens_per_mb_per_replica\": 2048,\n",
        "    \"precision\": \"bfloat16\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6XsDvJoAQVy",
        "outputId": "252c431c-d5e2-4c7b-e9a7-50a0b66447b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting configs/GPT3_2-7B.json\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%%writefile configs/GPT3_2-7B.json\n",
        "\n",
        "{\n",
        "     \"n_head\": 32,\n",
        "    \"n_vocab\": 50257,\n",
        "    \"embed_dropout\": 0,\n",
        "    \"lr\": 0.00016,\n",
        "    \"lr_decay\": \"cosine\",\n",
        "    \"warmup_steps\": 3000,\n",
        "    \"beta1\": 0.9,\n",
        "    \"beta2\": 0.95,\n",
        "    \"epsilon\": 1e-8,\n",
        "    \"ada_epsilon1\": 1e-30,\n",
        "    \"ada_epsilon2\": 1e-3,\n",
        "    \"opt_name\": \"adam\",\n",
        "    \"weight_decay\": 0.10,\n",
        "    \"train_batch_size\": 512,\n",
        "    \"attn_dropout\": 0,\n",
        "    \"train_steps\": 286150,\n",
        "    \"eval_steps\": 0,\n",
        "    \"predict_steps\": 1,\n",
        "    \"res_dropout\": 0,\n",
        "    \"eval_batch_size\": 128,\n",
        "    \"predict_batch_size\": 1,\n",
        "    \"iterations\": 500,\n",
        "    \"n_embd\": 2560,\n",
        "    \"datasets\": [\"Custom\"],\n",
        "    \"model_path\": \"gs://gpt3_demo/GPT3_2-7B\",\n",
        "    \"n_ctx\": 2048,\n",
        "    \"n_layer\": 32,\n",
        "    \"scale_by_depth\": true,\n",
        "    \"scale_by_in\": false,\n",
        "    \"attention_types\" :  [[[\"global\"],32]],\n",
        "    \"mesh_shape\": \"x:128,y:2\",\n",
        "    \"layout\": \"embd:y,batch:x\",\n",
        "    \"activation_function\": \"gelu\",\n",
        "    \"recompute_grad\": true,\n",
        "    \"gradient_clipping\": 1.0,\n",
        "    \"tokens_per_mb_per_replica\": 2048\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XwhZSP6yYME"
      },
      "source": [
        "Training from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7K9YA70dDsRQ"
      },
      "outputs": [],
      "source": [
        "!python3 main.py --model GPT3_XL3 --steps_per_checkpoint 200 --tpu colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "b_iWfekQaY3x"
      },
      "outputs": [],
      "source": [
        "# @title Download pretrained model weights:\n",
        "pretrained_model = 'GPT3_XL' #@param [\"GPT3_XL\", \"GPT3_2-7B\"]\n",
        "!wget -m -np -c -U \"eye02\" -w 2 -R \"index.html*\" \"https://the-eye.eu/public/AI/gptneo-release/$pretrained_model/\"\n",
        "path_to_local_weights = f\"/content/GPTNeo/the-eye.eu/public/AI/gptneo-release/GPT3_XL\"\n",
        "\n",
        "# URL = f\"http://eaidata.bmk.sh/data/gptneo-release/{pretrained_model}/\"\n",
        "# FOLDER_NAME = \"GPT3_XL\"\n",
        "# !curl $URL | grep -i \"</a>\" | sed -n 's/.*href=\"\\([^\"]*\\).*/\\1/p' | sed \"s|^|$URL|\" | xargs -n 1 -P 4 wget -P $pretrained_model\n",
        "# path_to_local_weights = pretrained_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bTTO6A1WdU1y"
      },
      "outputs": [],
      "source": [
        "# upload to your bucket\n",
        "path_to_local_weights = f\"/content/GPTNeo/GPTNeo/the-eye.eu/public/AI/gptneo-release/GPT3_XL\"\n",
        "bucket_base = \"gs://\" + path_to_cloud_bucket.replace('gs://', '').split('/')[0]\n",
        "!gsutil -m cp -r $path_to_local_weights $bucket_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjxnEvVpdeyY"
      },
      "outputs": [],
      "source": [
        "!gsutil ls $bucket_base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Laf0slBMDCUj"
      },
      "outputs": [],
      "source": [
        "# @title Modify config for colab.\n",
        "\n",
        "import json\n",
        "from pprint import pprint\n",
        "bucket_base = \"gs://gpt3_demo/\"\n",
        "path_to_model = \"\" #@param {type:\"string\"}\n",
        "batch_size = 8 #@param {type:\"integer\"}\n",
        "dset = \"\"  #@param {type:\"string\"}\n",
        "mesh_shape = \"x:4,y:2\" #@param {type:\"string\"}\n",
        "train_steps = 1000 #@param {type:\"integer\"}\n",
        "steps_per_checkpoint = 500 #@param {type:\"integer\"}\n",
        "start_step = 400000 if pretrained_model == \"GPT3_2-7B\" else 362000\n",
        "\n",
        "if path_to_model == \"\":\n",
        "  path_to_model = f'{bucket_base.strip(\"/\")}/{pretrained_model}'\n",
        "print(f'MODEL PATH: {path_to_model}\\n')\n",
        "\n",
        "if dset == \"\" and dataset != \"Sampling_Only\":\n",
        "  dset = dataset\n",
        "elif dataset is None and dset == \"\":\n",
        "  dset = \"pile\"\n",
        "\n",
        "def pad_to_multiple_of(n, mult):\n",
        "  \"\"\"\n",
        "  pads n to a multiple of mult\n",
        "  \"\"\"\n",
        "  extra = n % mult\n",
        "  if extra > 0:\n",
        "      n = n + mult - extra\n",
        "  return n\n",
        "\n",
        "with open(f'{path_to_local_weights}/config.json', 'r') as f:\n",
        "  data = json.load(f)\n",
        "  pprint(data)\n",
        "  dset_val = [[dset, None, None, None]] if dset != \"\" else data[\"datasets\"]\n",
        "  mods = {\n",
        "          \"mesh_shape\": mesh_shape,\n",
        "          \"layout\": \"intermediate_expanded:x,heads:x,memory_length:y,embd:y\",\n",
        "          \"model_path\": path_to_model,\n",
        "          \"datasets\": dset_val,\n",
        "          \"train_steps\": start_step + train_steps,\n",
        "          \"eval_steps\": 0,\n",
        "          \"train_batch_size\": batch_size,\n",
        "          \"predict_batch_size\": batch_size\n",
        "        }\n",
        "  data.update(mods)\n",
        "  print('\\n--->\\n')\n",
        "  pprint(data)\n",
        "  with open(f'configs/{pretrained_model}.json', 'w') as outfile:\n",
        "    json.dump(data, outfile, indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e07cdT4vy0et"
      },
      "source": [
        "Training from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XaHZJOewy1Xa"
      },
      "outputs": [],
      "source": [
        "!python3 main.py --model $pretrained_model --steps_per_checkpoint $steps_per_checkpoint --tpu colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Gdq0eDxfhoP",
        "outputId": "9ddfea50-6e23-4cb9-90a3-54d8fbf1576c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting example_prompt.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile example_prompt.txt\n",
        "Transform code to requirement:\n",
        "code:\n",
        "package interfacce;\n",
        "import java.awt.*;\n",
        "import java.awt.event.*;\n",
        "import common.utility.*;\n",
        "import common.def.*;\n",
        "import java.util.Date;\n",
        "import moduli.*;\n",
        "\n",
        "public class VediPrenotazione extends MascheraPrenotazione\n",
        "{  \n",
        " Prenotazione p;    \n",
        "    RicercaPrenotazione parent;\n",
        "    char flag;\n",
        "    \n",
        "    public VediPrenotazione(Prenotazione pren, Stanza room, RicercaPrenotazione papa)\n",
        "    {\n",
        "        super(room,\"\",\"\",\"Visualizzazione dei dati della prenotazione\",\"\",4, pren.getPensionamento());\n",
        "        p = pren;\n",
        "        parent = papa;\n",
        "        init();\n",
        "    }\n",
        "        \n",
        "    public void init()\n",
        "    {\n",
        "     Frame msg;\n",
        "     \n",
        "     writeDatiPren(p);\n",
        "     for(int i=0; i<11; i++)\n",
        "      testo[i].setEditable(false);\n",
        "     myCheckbox.setEnabled(false);\n",
        "     myCheckbox1.setEnabled(false);\n",
        "     for (int i=0; i<checkboxes.length; i++)\n",
        "      checkboxes[i].setEnabled(false);\n",
        "     testo[9].setText(DateUtils.parseDate(DateUtils.giveStringOfDate(p.getDataPren())));     \n",
        "      panel2.remove(Azione);\n",
        "    } \n",
        "}\n",
        "requirement:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv-wr9KSRhS9"
      },
      "outputs": [],
      "source": [
        "!python3 main.py --model GPT3_XL3 --steps_per_checkpoint 500 --tpu colab --predict --prompt example_prompt.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTpUq-5IfmkH"
      },
      "outputs": [],
      "source": [
        "!python3 main.py --model GPT3_2-7B --steps_per_checkpoint 500 --tpu colab --predict --prompt example_prompt.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhHM1GHaO073"
      },
      "source": [
        "Begin Fine-Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1xshxFeyO1kt"
      },
      "outputs": [],
      "source": [
        "!python3 main.py --model $pretrained_model --steps_per_checkpoint $steps_per_checkpoint --tpu colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sb-as3FRWnyS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}